{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(своя тема)\n",
    "Это анализатор для трех сообществ вконтакте (новостное, футбольное и историческое). \n",
    "Для каждого сообщества программа находит самое популярное слово за последние 100 постов (без учета стоп-слов) и, используя его \n",
    "как начальный узел для семантического поля, строит граф. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f5ca4c471257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnaconda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#import gensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "#from pymystem3 import Mystem\n",
    "import Anaconda\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from networkx.algorithms import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words():\n",
    "    vk_ids = ['-29534144', '-217557', '-95380917']\n",
    "    tops = ''\n",
    "    \n",
    "    for i in vk_ids:\n",
    "        vk_id = i\n",
    "        \n",
    "        token = 'ce9bbc81ce9bbc81ce9bbc81f7cef1aec5cce9bce9bbc8192236d' \\\n",
    "                '27163fe4bf62eb1946'\n",
    "        req = urllib.request.Request(\n",
    "        'https://api.vk.com/method/wall.get?owner_id=%s&count=5&'\n",
    "        'access_token=%s&v=5.95' % (vk_id, token))\n",
    "        response = urllib.request.urlopen(req)\n",
    "        result = response.read().decode('utf-8')\n",
    "        data = json.loads(result)\n",
    "        posts = data['response']['items']\n",
    "        \n",
    "        all_text = ''\n",
    "        #m = Mystem()\n",
    "        #sw = stopwords.words('russian')\n",
    "\n",
    "        for post in posts:\n",
    "            text = post['text']\n",
    "            plain = re.sub('[^а-яА-Я\\s]', '', text)\n",
    "            all_text += plain\n",
    "            \n",
    "            \n",
    "        m = Mystem()\n",
    "        lemmas = m.lemmatize(str(all_text))\n",
    "        #print(lemmas)\n",
    "        \n",
    "        top_lem = Counter(lemmas)\n",
    "        top_lem = dict(top_lem)\n",
    "        top_lem = {c: top_lem[c] for c in top_lem if top_lem[c] > 2 and len(c) > 2}\n",
    "        top_lem = (sorted(top_lem.items(), key=lambda x: x[1], reverse=True))[:1]\n",
    "        \n",
    "        print(top_lem)\n",
    "        \n",
    "        for i in dict(top_lem).keys():\n",
    "            tops += i + ' '\n",
    "        \n",
    "    with open('tops.txt', 'w+', 'encoding=utf-8') as f:\n",
    "        f.write(tops)\n",
    "            \n",
    "        #new_lines = []\n",
    "        #for line in all_text:\n",
    "            #line = ' '.join([w for w in line.split() if w not in sw])\n",
    "        #    newline = ''.join(m.lemmatize(line))\n",
    "        #    new_lines.append(newline)\n",
    "            \n",
    "        #print(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('задерживать', 6)]\n",
      "[]\n",
      "[('тайна', 3)]\n",
      "задерживатьтайна\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-828b1ebfb210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tops' is not defined"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    'http://rusvectores.org/static/models/rusvectores2/'\n",
    "    'ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
    "    'ruscorpora_mystem_cbow_300_2_2015.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
    "\n",
    "if m.endswith('.vec.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
    "elif m.endswith('.bin.gz'):\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "else:\n",
    "    model = gensim.models.KeyedVectors.load(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tops.txt', 'r', 'encoding=utf-8') as f:\n",
    "    words = list(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# список с соседями первого порядка\n",
    "level_one = []\n",
    "\n",
    "for word in words:\n",
    "    if word in model:\n",
    "        print(word)\n",
    "        word_part = str(word)[-1:]\n",
    "        print(word_part)\n",
    "        #  количество слов-соседей для первого узла\n",
    "        syn_words = len(model[word])\n",
    "        for i in model.most_similar(positive=[word], topn=syn_words):\n",
    "            if i[1] >= 0.5 and str(i[0])[-1:] == word_part:\n",
    "                level_one.append(i[0])\n",
    "                G.add_node(i[0], label=str(i[0]))\n",
    "                G.add_edge(str(word), str(i[0]))\n",
    "    else:\n",
    "        print('Увы, слова \"%s\" нет в модели!' % word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
