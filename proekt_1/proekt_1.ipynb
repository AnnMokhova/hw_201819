{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import os\n",
    "import html\n",
    "import csv\n",
    "\n",
    "\n",
    "def open_page():\n",
    "    dirname = 'newspaper'\n",
    "    path_dirname = '%s' % dirname\n",
    "    if not os.path.exists(path_dirname):\n",
    "        os.makedirs(path_dirname)\n",
    "    filename = '/metadata.csv'\n",
    "    path = path_dirname + filename\n",
    "    # в созданном csv-файле пишет имена полей\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write('path\\tauthor\\theader\\tcreated\\tsphere\\ttopic\\tstyle\\\n",
    "                 \\taudience_age\\taudience_level\\taudience_size\\tsource\\\n",
    "                 \\tpublication\\tpubl_year\\tmedium\\tcountry\\tregion\\\n",
    "                 \\tlanguage\\n')\n",
    "    \n",
    "    # ссылка на газету\n",
    "    newspaper_Url = 'https://hron.ru/news/read/'\n",
    "    \n",
    "    for i in range(55250, 56249):   # (55250, 56249)\n",
    "        pageUrl = newspaper_Url + str(i)\n",
    "        try:\n",
    "            page = urllib.request.urlopen(pageUrl)\n",
    "            html = page.read().decode('utf-8')\n",
    "            # print(html)\n",
    "        except:\n",
    "            # print('Error at', pageUrl)\n",
    "            continue\n",
    "            return\n",
    "        # clean_html(html)\n",
    "        page = str(pageUrl)\n",
    "        search_meta(search_author(html), search_date(html),\n",
    "                    search_header(html), pageUrl, path, path_dirname,\n",
    "                    article(html))\n",
    "        \n",
    "    return html\n",
    "\n",
    "\n",
    "def search_meta(author, date, header, pageUrl, path, path_dirname, article):\n",
    "    \n",
    "    path_plain = path_dirname + '\\plain' \n",
    "    if not os.path.exists(path_plain):\n",
    "        os.makedirs(path_plain)\n",
    "    year = str(''.join(date))[6:10]\n",
    "    year_dirname = '%s' % year\n",
    "    path_year = os.path.join(path_plain, year_dirname)\n",
    "    if not os.path.exists(path_year):\n",
    "        os.makedirs(path_year)\n",
    "    month = month = str(''.join(date))[3:5]\n",
    "    month_dirname = '%s' % month\n",
    "    path_month = os.path.join(path_year, month_dirname)\n",
    "    if not os.path.exists(path_month):\n",
    "        os.makedirs(path_month)\n",
    "    \n",
    "    art_name = 'article' + str(pageUrl)[-5:] + '.txt'\n",
    "    art_path = os.path.join(path_month, art_name)\n",
    "    info = '@au' + author + '\\n@ti' + header + '\\n@da' + date + '\\n@topic' + \\\n",
    "           'None' + '\\n@url' + pageUrl + '\\n'\n",
    "    with open(art_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(info)\n",
    "    with open(art_path, 'a+', encoding='utf-8') as fl:\n",
    "        fl.write(article)\n",
    "        \n",
    "    meta = '%s\\t%s\\t%s\\t%s\\tпублицистика\\tNone\\tнейтральный\\tн-возраст\\\n",
    "            \\tн-уровень\\tгородская\\t%s\\tОрская хроника\\t%s\\tгазета\\tРоссия\\\n",
    "            \\tОренбургская область\\tru\\n'\n",
    "    \n",
    "    meta_string = meta % (art_path, author, header, date, pageUrl, \n",
    "                          str(''.join(date))[6:10])\n",
    "    # print(meta_string)\n",
    "    with open(path, 'a') as f:\n",
    "        f.write(meta_string)\n",
    "\n",
    "    \n",
    "def search_author(html):  # находит имя автора\n",
    "    author = re.findall(r'<a href=\"/author/single/\\w+\" title=\"(.*?)\">', \n",
    "                        html)\n",
    "    author = ''.join(author)\n",
    "    if author == '':\n",
    "        author = 'None'\n",
    "    return author\n",
    "\n",
    "\n",
    "def search_date(html):  # находит дату статьи\n",
    "    date = re.findall(r'<li class=\"detail date\">(.*?)</li>', html)\n",
    "    date = ''.join(date)\n",
    "    date = date.replace('-', '.')\n",
    "    return date\n",
    "\n",
    "\n",
    "def search_header(html):  # находит название статьи\n",
    "    header = re.findall(\n",
    "        r'<title>(.*?)Ежедневная городская газета Орская хроника</title>', \n",
    "        html)\n",
    "    header = ''.join(header)\n",
    "    return header\n",
    "\n",
    "\n",
    "def article(html):  # находит и чистит текст статьи\n",
    "    article = re.findall(\n",
    "        r'<div class=\"text\">\\n(.*?)</div>', html)\n",
    "    article = ''.join(str(x) for x in article)\n",
    "    regTag = re.compile('<.*?>', re.DOTALL)\n",
    "    article = regTag.sub('', article)\n",
    "    regNBSP = re.compile('[&nbsp;]', re.DOTALL)\n",
    "    article = regNBSP.sub('', article)\n",
    "    # print(article)\n",
    "    return article\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    open_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
